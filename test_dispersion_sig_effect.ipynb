{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sensitivity_class import *\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Previously the dispersion_sig constant in linear_lnlike.py was set to 1.5 and resulted in many planet detections (1065 out of 1760 injected planets) but also many false positives (N=2339) in the single multiplicity scenario. To try and reduce the number of FPs I'm increasing with the dispersion_sig value to reduce FPs but will consequently reduce the planet detections as well. Let's try and see by how much here..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1065.0 1760 2339\n"
     ]
    }
   ],
   "source": [
    "# get data\n",
    "self = loadpickle('Results/TOIsensitivity27vett_mult1_SensitivityGrid_dissig1d5_depthsig1d5')\n",
    "print self.detected.sum(), self.detected.size, self.PsFP.size"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Change dispersion_sig in linear_lnlike.py and run through confirm_transits. Then count the new number of FPs and planet detections to gauge if the change is globally beneficial."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from linear_lnlike_testconstants import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_statistics(fs, Nplanets, dispersion_sig=2.1, depth_sig=1.5):\n",
    "    '''run confirm transits on some saved light curves but with differing constant values to see \n",
    "    their effect on the number of detected planets and the number of false positives'''\n",
    "    assert fs.size > 0\n",
    "    Ndets, Ntrues, NFPs = 0, 0, 0\n",
    "    for i in range(fs.size):\n",
    "        d = loadpickle(fs[i])\n",
    "        paramsout,_,_=confirm_transits(d.params_guess_priorto_confirm, d.bjd, d.fcorr, d.ef, d.Ms, d.Rs, d.Teff, \n",
    "                                       dispersion_sig, depth_sig)\n",
    "        for j in range(Nplanets):\n",
    "            Ndets += np.isclose(paramsout[:,0], d.params_true[j:j+1,0], atol=.2).sum()\n",
    "            Ntrues += 1\n",
    "            NFPs += paramsout.shape[0]-np.isclose(paramsout[:,0], d.params_true[j:j+1,0], atol=.2).sum()\n",
    "    sens = Ndets/float(Ntrues)\n",
    "    return Ndets, Ntrues, sens, NFPs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confirming proposed transits...\n",
      "0.0\n",
      "0.2\n",
      "0.4\n",
      "0.6\n",
      "0.8\n",
      "1.5 1.5\n",
      "Confirming proposed transits...\n",
      "0.0\n",
      "0.1\n",
      "0.2\n",
      "0.3\n",
      "0.4\n",
      "0.5\n",
      "0.6\n",
      "0.7\n",
      "0.8\n",
      "0.9\n",
      "1.5 1.5\n"
     ]
    }
   ],
   "source": [
    "# get lcs files that I have saved and rerun confirm_transits with different constant values\n",
    "Nplanets = 2\n",
    "fs = np.array(glob.glob('Results/TOIsensitivity27vett_mult%i_planet000*010/S*'%Nplanets))\n",
    "Ndets1, Ntrues1, sens1, NFPs1 = get_statistics(fs, Nplanets, 1.5, 1.5)\n",
    "Ndets2, Ntrues2, sens2, NFPs2 = get_statistics(fs, Nplanets, 2.1, 1.5)\n",
    "Ndets3, Ntrues3, sens3, NFPs3 = get_statistics(fs, Nplanets, 2.5, 1.5)\n",
    "Ndets4, Ntrues4, sens4, NFPs4 = get_statistics(fs, Nplanets, 2.1, 2.1)\n",
    "Ndets5, Ntrues5, sens5, NFPs5 = get_statistics(fs, Nplanets, 2.1, 3)\n",
    "Ndets6, Ntrues6, sens6, NFPs6 = get_statistics(fs, Nplanets, 3, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print Nplanets\n",
    "print 'dispersion_sig=1.5, depth_sig=1.5:', Ndets1, Ntrues1, sens1, NFPs1\n",
    "print 'dispersion_sig=2.1, depth_sig=1.5:', Ndets2, Ntrues2, sens2, NFPs2\n",
    "print 'dispersion_sig=2.5, depth_sig=1.5:', Ndets3, Ntrues3, sens3, NFPs3\n",
    "print 'dispersion_sig=2.1, depth_sig=2.1:', Ndets4, Ntrues4, sens4, NFPs4\n",
    "print 'dispersion_sig=2.1, depth_sig=3.0:', Ndets5, Ntrues5, sens5, NFPs5\n",
    "print 'dispersion_sig=3.0, depth_sig=3.0:', Ndets6, Ntrues6, sens6, NFPs6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
